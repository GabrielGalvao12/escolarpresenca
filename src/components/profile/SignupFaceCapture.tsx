import { useRef, useEffect, useState } from "react";
import { Button } from "@/components/ui/button";
import { toast } from "sonner";
import * as faceapi from "face-api.js";
import { Camera, Loader2, CheckCircle2, X } from "lucide-react";

interface SignupFaceCaptureProps {
  onCapture: (descriptor: number[]) => void;
  onReset: () => void;
  isCaptured: boolean;
}

const SignupFaceCapture = ({ onCapture, onReset, isCaptured }: SignupFaceCaptureProps) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [loading, setLoading] = useState(true);
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [capturing, setCapturing] = useState(false);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [showCamera, setShowCamera] = useState(false);

  useEffect(() => {
    if (showCamera) {
      (async () => {
        await loadModels();
        await startVideo();
      })();
    }
    return () => {
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, [showCamera]);

  const loadModels = async () => {
    try {
      console.log("Carregando modelos de reconhecimento facial...");

      // Caminho local (mais r√°pido e confi√°vel)
      const LOCAL_MODEL_URL = "/models";
      const CDN_MODEL_URL = "https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model";

      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(LOCAL_MODEL_URL),
          faceapi.nets.faceLandmark68Net.loadFromUri(LOCAL_MODEL_URL),
          faceapi.nets.faceRecognitionNet.loadFromUri(LOCAL_MODEL_URL),
        ]);
        console.log("‚úÖ Modelos carregados localmente com sucesso");
      } catch (localError) {
        console.warn("‚ö†Ô∏è Modelos locais n√£o encontrados, tentando CDN...");
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(CDN_MODEL_URL),
          faceapi.nets.faceLandmark68Net.loadFromUri(CDN_MODEL_URL),
          faceapi.nets.faceRecognitionNet.loadFromUri(CDN_MODEL_URL),
        ]);
        console.log("‚úÖ Modelos carregados via CDN com sucesso");
      }

      setModelsLoaded(true);
    } catch (error) {
      console.error("‚ùå Erro ao carregar modelos:", error);
      toast.error("Erro ao carregar modelos de reconhecimento facial");
      setLoading(false);
    }
  };

  const startVideo = async () => {
    try {
      console.log("üé• Solicitando permiss√£o de c√¢mera...");
      
      // Verificar se est√° em ambiente seguro
      if (window.location.protocol !== "https:" && window.location.hostname !== "localhost") {
        toast.warning("‚ö†Ô∏è A c√¢mera funciona melhor em HTTPS ou localhost");
      }
      
      // Check if getUserMedia is supported
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        toast.error("Seu navegador n√£o suporta acesso √† c√¢mera. Use HTTPS ou localhost.");
        setLoading(false);
        return;
      }

      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: { 
          facingMode: "user",
          width: { ideal: 1280 },
          height: { ideal: 720 }
        },
      });
      
      console.log("‚úÖ Permiss√£o concedida, iniciando v√≠deo...");
      
      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
        setStream(mediaStream);
        
        // Wait for video metadata to load
        videoRef.current.onloadedmetadata = async () => {
          try {
            await videoRef.current!.play();
            console.log("üé• V√≠deo iniciado com sucesso");
            setLoading(false);
          } catch (playError) {
            console.error("‚ùå Erro ao reproduzir v√≠deo:", playError);
            toast.error("Erro ao iniciar v√≠deo da c√¢mera");
            setLoading(false);
          }
        };
      }
    } catch (error: any) {
      console.error("‚ùå Erro ao acessar c√¢mera:", error);
      
      if (error.name === "NotAllowedError") {
        toast.error("üö´ Permiss√£o de c√¢mera negada. Por favor, permita o acesso √† c√¢mera.");
      } else if (error.name === "NotFoundError") {
        toast.error("üì∑ Nenhuma c√¢mera encontrada no dispositivo.");
      } else if (error.name === "NotReadableError") {
        toast.error("‚ö†Ô∏è C√¢mera em uso por outro aplicativo.");
      } else {
        toast.error("‚ùå Erro ao acessar c√¢mera. Verifique se est√° usando HTTPS ou localhost.");
      }
      
      setLoading(false);
    }
  };

  const captureFace = async () => {
    if (!videoRef.current || !canvasRef.current || !modelsLoaded) {
      toast.error("C√¢mera ou modelos n√£o est√£o prontos");
      return;
    }

    setCapturing(true);
    toast.info("Detectando rosto...");

    try {
      // Pause video during capture
      videoRef.current.pause();

      const detection = await faceapi
        .detectSingleFace(videoRef.current, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!detection) {
        toast.error("Nenhum rosto detectado. Posicione seu rosto na c√¢mera e tente novamente.");
        setCapturing(false);
        // Resume video
        if (videoRef.current) {
          videoRef.current.play();
        }
        return;
      }

      // Draw the detected face on canvas for preview
      const canvas = canvasRef.current;
      const displaySize = { 
        width: videoRef.current.videoWidth, 
        height: videoRef.current.videoHeight 
      };
      faceapi.matchDimensions(canvas, displaySize);
      
      const resizedDetections = faceapi.resizeResults(detection, displaySize);
      canvas.getContext('2d')?.clearRect(0, 0, canvas.width, canvas.height);
      faceapi.draw.drawDetections(canvas, resizedDetections);
      faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

      const descriptor = Array.from(detection.descriptor);
      
      // Stop camera
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        setStream(null);
      }
      
      setShowCamera(false);
      onCapture(descriptor);
      toast.success("Foto facial capturada com sucesso!");
    } catch (error) {
      console.error("Error capturing face:", error);
      toast.error("Erro ao processar rosto. Tente novamente.");
      setCapturing(false);
      // Resume video on error
      if (videoRef.current) {
        videoRef.current.play();
      }
    }
  };

  const handleReset = () => {
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      setStream(null);
    }
    setShowCamera(false);
    setLoading(true);
    setModelsLoaded(false);
    onReset();
  };

  if (isCaptured) {
    return (
      <div className="space-y-2">
        <div className="flex items-center justify-between p-4 bg-primary/10 border border-primary/20 rounded-lg">
          <div className="flex items-center gap-2">
            <CheckCircle2 className="w-5 h-5 text-primary" />
            <span className="font-medium">Foto facial capturada</span>
          </div>
          <Button
            type="button"
            variant="ghost"
            size="sm"
            onClick={handleReset}
          >
            <X className="w-4 h-4 mr-1" />
            Refazer
          </Button>
        </div>
      </div>
    );
  }

  if (!showCamera) {
    return (
      <div className="space-y-2">
        <div className="p-4 bg-muted/50 border border-border rounded-lg">
          <div className="flex items-start gap-3 mb-4">
            <Camera className="w-5 h-5 text-primary mt-0.5" />
            <div className="flex-1">
              <p className="font-medium mb-1">Cadastro Facial Obrigat√≥rio</p>
              <p className="text-sm text-muted-foreground">
                Voc√™ precisa cadastrar seu rosto para concluir o registro e poder marcar presen√ßa futuramente.
              </p>
            </div>
          </div>
          <Button
            type="button"
            onClick={() => setShowCamera(true)}
            className="w-full"
            variant="outline"
          >
            <Camera className="w-4 h-4 mr-2" />
            Abrir C√¢mera
          </Button>
        </div>
      </div>
    );
  }

  return (
    <div className="space-y-3">
      <div className="relative rounded-lg overflow-hidden bg-black aspect-video border-2 border-primary/20">
        {loading ? (
          <div className="absolute inset-0 flex flex-col items-center justify-center gap-4">
            <Loader2 className="w-8 h-8 animate-spin text-white" />
            <p className="text-white text-sm">
              {!modelsLoaded ? "Carregando modelos de reconhecimento..." : "Iniciando c√¢mera..."}
            </p>
          </div>
        ) : (
          <>
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
              className="w-full h-full object-cover"
              onLoadedMetadata={() => {
                if (videoRef.current) {
                  const { videoWidth, videoHeight } = videoRef.current;
                  if (canvasRef.current) {
                    canvasRef.current.width = videoWidth;
                    canvasRef.current.height = videoHeight;
                  }
                }
              }}
            />
            <canvas ref={canvasRef} className="absolute top-0 left-0" />
            
            {/* Face guideline overlay */}
            <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
              <div className="w-48 h-60 border-4 border-primary rounded-full opacity-50"></div>
            </div>
          </>
        )}
      </div>

      <div className="space-y-1.5 text-xs text-muted-foreground">
        <div className="flex items-start gap-2">
          <CheckCircle2 className="w-3.5 h-3.5 mt-0.5 flex-shrink-0" />
          <span>Posicione seu rosto no centro da moldura</span>
        </div>
        <div className="flex items-start gap-2">
          <CheckCircle2 className="w-3.5 h-3.5 mt-0.5 flex-shrink-0" />
          <span>Certifique-se de estar em um local bem iluminado</span>
        </div>
      </div>

      <div className="grid grid-cols-2 gap-2">
        <Button
          type="button"
          variant="outline"
          onClick={handleReset}
          disabled={capturing}
        >
          Cancelar
        </Button>
        <Button
          type="button"
          onClick={captureFace}
          disabled={loading || !modelsLoaded || capturing}
        >
          {capturing ? (
            <>
              <Loader2 className="mr-2 h-4 w-4 animate-spin" />
              Detectando rosto...
            </>
          ) : (
            <>
              <Camera className="mr-2 h-4 w-4" />
              {modelsLoaded ? "Capturar Foto" : "Carregando..."}
            </>
          )}
        </Button>
      </div>
    </div>
  );
};

export default SignupFaceCapture;
